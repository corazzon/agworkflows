---
description: 1. 범용 웹 데이터 수집 (Network Traffic Based)
---

// turbo-all

1. **[환경]** `uv` 및 필수 라이브러리(`requests`, `pandas`) 설치를 확인합니다.
2. **[정보 확인]** 사용자에게 다음 양식에 맞춰 네트워크 정보를 제공해달라고 요청하거나, 대화 맥락에서 이미 제공되었는지 확인합니다.
    > "데이터 수집을 위해 다음 정보를 알려주시거나, 개발자 도구의 네트워크 탭 내용을 복사해 주세요:"
    > a. 네트워크 메뉴를 통해 실제 데이터를 가져오는 URL
    > b. 해당 Request에 대한 Header 정보
    > c. Payload
    > d. 응답 예시 (HTML, JSON 의 일부 정보)
3. **[크롤러 작성]** 제공된 정보를 바탕으로 `src/crawlers/custom_crawler.py`를 작성합니다.
    - **핵심 로직**:
        - 위 a~d 정보를 그대로 코드에 반영합니다.
        - **페이지네이션**: 1페이지부터 5페이지까지 반복 요청하는 루프를 구현합니다. (쿼리 파라미터나 Payload의 page 관련 변수를 수정)
        - **로깅**: `print(f"[INFO] {page}페이지 수집 중...")` 형태로 중간 과정을 출력하게 합니다.
    - **저장**: 최종 결과를 `data/raw/result.csv`로 저장합니다.
4. **[실행]** 작성된 스크립트를 실행합니다.
5. **[안내]** 수집이 완료되면, "이제 `/2_analyze`를 실행하여 분석을 진행하세요."라고 안내합니다.